---
icon: lucide/network
tags:
  - Government
  - Policy
  - Governance
  - International
---

# AI Safety Coordination

## Overview

Effective coordination across government, between jurisdictions, and internationally is essential for managing AI risks. No single institution can address all aspects of AI safety—success requires clear processes for information sharing, joint decision-making, and escalation when agencies disagree.

This page outlines **what effective coordination looks like** based on international practice and Australian experience with complex cross-government challenges. It covers:

- AISI and sectoral regulator coordination
- Cross-government coordination mechanisms
- Federal-state coordination
- International coordination through the AISI
- Integration with national security and resilience frameworks

The approaches described here represent comprehensive coordination frameworks—what works internationally and what Australia's existing coordination experience suggests is effective.

---

## AISI and sectoral regulator coordination

The AISI provides concentrated evaluation capability. Sectoral regulators provide domain expertise and enforcement authority. Effective coordination between them is what makes the system work.

!!! success "What good coordination looks like"

    **Clear division of responsibilities** prevents gaps and duplication. The AISI focuses on technical evaluation, standards development, and international coordination. Sectoral regulators—APRA for financial services, TGA for medical devices, OAIC for privacy, ACCC for competition—handle domain-specific oversight, enforcement, and apply their deep sectoral expertise. Clear processes connect evaluation results to regulatory action: when AISI identifies risks in a system, the relevant regulator knows what authority they have and what steps to take.

**Information sharing flows both ways.** AISI shares evaluation results with regulators who need them—not broadcasting everything publicly, but ensuring those with oversight responsibility have what they need. Regulators share deployment information and incident reports back to AISI, creating feedback loops that improve evaluation methodologies. Protected channels handle sensitive information about system vulnerabilities that could be weaponised if leaked.

**Joint decision-making processes** handle the complex cases. High-risk system approvals involve both AISI technical evaluation and sectoral regulator judgment about deployment context. Clear escalation processes exist when technical evaluation conflicts with sectoral judgment—both perspectives matter, and neither should be able to override the other without deliberation. Regular coordination meetings and joint planning maintain relationships before crises hit.

!!! example "International examples"

    **UK model:** AI Safety Institute evaluates systems; sectoral regulators enforce using existing authority

    **US model:** NIST AI Safety Institute provides frameworks; federal agencies implement in their domains

    **EU model:** AI Office coordinates overall approach; member state authorities enforce AI Act requirements

---

## Cross-government coordination mechanisms

AI risks cut across portfolios—Industry, Home Affairs, Defence, Health, Treasury, Attorney-General's all have relevant responsibilities. Effective coordination prevents gaps where risks fall between agencies and duplication where multiple agencies address the same issue without talking to each other.

**What coordination mechanisms do:**

Effective mechanisms prevent gaps, prevent duplication, enable information sharing and joint decision-making, and provide escalation pathways when agencies disagree. They're not bureaucratic overhead—they're how government maintains coherent strategy when responsibilities are distributed.

**Common approaches from Australian practice:**

**Interdepartmental coordination** brings together officials from relevant departments and agencies for regular meetings, with subgroups for specific issues. Examples include National Security Committee processes and the Critical Infrastructure Centre. This works when relationships are strong and issues are well-understood, but can struggle with rapid response or when agencies have genuinely conflicting priorities.

**Lead department models** designate one department (like Industry for AI policy) as coordination lead while other agencies retain their functions. The lead department convenes meetings, sets agendas, and helps resolve disputes. This creates clearer accountability than committee-only approaches but requires the lead department to have genuine authority and respect from other agencies.

**Ministerial-level coordination** through Cabinet committees or ministerial councils handles strategic decisions and high-stakes cross-portfolio issues. Examples include the National Security Committee of Cabinet and National Cabinet. This is slower than officials-level coordination but carries political authority when needed.

**Crisis coordination** provides standing capability that activates during crises, with pre-established relationships and processes tested through regular exercises. The National Coordination Mechanism for emergency management provides a model. AI-related crises could require similar rapid whole-of-government response.

!!! tip "Requirements for effective coordination"

    Clear terms of reference defining what the coordination mechanism is for, who participates, and how decisions are made. Secretariat support to organize meetings, track decisions, and follow up on actions. Regular meetings—coordination doesn't work if bodies only meet when crises hit. Escalation pathways for when coordination fails or urgent decisions are needed.

---

## State and territory coordination

Many policy levers sit with states and territories—health systems, education, justice, much critical infrastructure. AI systems deployed in state-run hospitals or schools need governance, but federal authority is limited. Effective federal-state coordination is essential.

**What good federal-state coordination achieves:**

Consistency where it matters—industry faces lower compliance burden when standards are nationally coherent. Shared expertise where capability varies—some states have more AI expertise than others, coordination can distribute learning. Experimentation where appropriate—states can be laboratories, testing different approaches before national adoption. Rapid information sharing when incidents occur—failures in one jurisdiction provide lessons for others.

**Common approaches:**

**National Cabinet processes** enable federal and state leaders to coordinate on AI policy frameworks at the highest level. This carries political weight but moves slowly and works best for strategic direction rather than operational detail.

**Ministerial councils** bring together federal and state ministers in specific portfolios—health ministers coordinating on AI in healthcare, education ministers on AI in schools. These combine sectoral expertise with federal-state coordination.

**Model legislation** allows the Commonwealth to develop template laws that states adapt to their context. This enables consistency while respecting state sovereignty and different local needs.

**Information sharing agreements** formalize arrangements on standards and mutual recognition. When one state evaluates a system for deployment, others can recognise that evaluation rather than duplicating effort.

**Australian context:**

Some states have more capability than others—coordination can share expertise and prevent duplication. A consistent national approach reduces industry compliance burden, particularly for systems deployed across multiple jurisdictions. But states are also laboratories—some variation enables experimentation and learning. Federal funding can encourage consistency where needed without removing all state flexibility.

---

## International coordination through the AISI

The AISI's participation in the International Network of AI Safety Institutes positions Australia to engage as an equal partner with UK, US and other leading safety institutes. This is critical—dangerous AI capabilities cross borders, and unilateral action isn't sufficient.

**What effective international coordination enables:**

**Shared evaluation methodologies** reduce duplication and improve quality. When Australia, UK and US coordinate on testing frameworks, we avoid reinventing the same methods and learn from each other's findings. Building common understanding of dangerous capabilities helps everyone recognise risks earlier.

**Threat intelligence exchange** enables Australia to learn from system vulnerabilities and failures discovered elsewhere, coordinate on incidents affecting multiple jurisdictions, and benefit from other countries' regulatory experiences. This requires trusted relationships—not all threat information can be shared publicly, but sharing within the safety institutes network enables faster response.

**Harmonized standards** work toward mutual recognition of evaluations—if UK AISI evaluates a system, Australia might recognise that rather than duplicating work. Common approaches to risk classification reduce compliance burden for systems deployed internationally. Interoperable incident reporting enables cross-border learning from failures.

**Maintaining regulatory sovereignty** means international coordination doesn't require identical regulations. Australia retains authority over what's deployed within our jurisdiction. The balance is cooperation where essential (evaluation methods, threat intelligence) and independence where it matters (deployment decisions based on Australian context and priorities).

**Why this matters for Australia:**

We import most frontier AI—models are trained overseas but deployed here. International coordination provides visibility into systems we don't develop ourselves. Our allies face similar challenges as middle powers managing risks from AI they don't control. Participating as equal partners in the AI Safety Institutes Network gives Australia influence disproportionate to our size and ensures our interests are represented in international standards development.

---

## Integration with national security and resilience frameworks

AI and AGI risks don't fit neatly into "national security" or "civilian regulation." They span both. Effective coordination bridges security agencies and civilian regulators without compromising necessary secrecy or creating gaps.

**Why integration matters:**

Defence and intelligence agencies assess AI-enabled threats—cyber operations, information warfare, autonomous weapons systems. They evaluate AI used in national security functions and contribute horizon scanning for dangerous capabilities emerging from frontier AI research. Home Affairs coordinates national resilience, critical infrastructure protection, and counter-foreign interference—all directly relevant to AI risks. These agencies have expertise and information civilian regulators need, but work in classified environments.

**Coordination challenges:**

Security agencies work in classified environments while civilian regulators need unclassified information to function. Different risk tolerances and priorities exist—security agencies may accept risks civilians won't, or vice versa. Sharing threat intelligence without compromising sources requires careful mechanisms. These challenges are real but not insurmountable—Australia has long experience coordinating security and civilian functions.

**What good integration looks like:**

**Formal liaison arrangements** between civilian AI safety functions (like AISI) and security agencies create regular touchpoints without requiring full disclosure. Officers from each side understand what the other needs and what they can share.

**Shared threat assessment processes** bring together security, regulatory, and policy perspectives without requiring everyone to have access to all information. Classified and unclassified workstreams run in parallel—sensitive intelligence informs decisions without requiring full disclosure to civilian participants.

**National Risk Register integration** ensures AI risks are assessed alongside other national threats using consistent methodology. This prevents AI risks being siloed from broader risk management.

**Australian context:**

Australia has strong institutions—ASIO, ASD, Defence—with relevant expertise and history of effective civil-military coordination. Five Eyes relationships enable intelligence sharing on AI threats with trusted partners. The opportunity exists to position AI safety as both a security and civilian issue from the start, avoiding artificial separation that creates gaps.

---

## Making coordination work in practice

!!! tip "What makes coordination effective"

    Coordination fails when it's just more meetings without clear purpose or authority. What makes it work:

    **Start before crisis.** Build relationships and processes during peacetime, test them through exercises, ensure people know each other before they need to coordinate under pressure.

    **Invest in secretariat capability.** Good coordination requires administrative support—organizing meetings, tracking decisions, following up on actions, maintaining institutional memory.

    **Use technology appropriately.** Shared systems for incident reporting, secure channels for sensitive information, dashboards showing who's responsible for what—these enable coordination at scale.

    **Accept that perfect coordination is impossible.** Some gaps and overlaps will exist. The goal is to know where they are and have mechanisms to address them when they matter.

    **Learn from failures.** When coordination breaks down, understand why and fix the underlying issue rather than just adding another coordination layer.

For detailed analysis of coordination approaches and trade-offs, see the [For Researchers](../for-researchers.md#coordination) section.

---

## Sources & Further Reading

??? note "International coordination examples"

    **AI Safety Institutes Network:**

    - [International Network of AI Safety Institutes](https://www.aisafetyinstitutesnetwork.org/)
    - [UK AI Safety Institute](https://www.gov.uk/government/organisations/ai-safety-institute)
    - [US AI Safety Institute (NIST)](https://www.nist.gov/aisi)

    **International agreements:**

    - [Bletchley Declaration](https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration) (AI Safety Summit 2023)
    - [Seoul Declaration](https://www.gov.uk/government/publications/ai-seoul-summit-2024-joint-leaders-statement) (AI Seoul Summit 2024)
    - [OECD AI Principles](https://oecd.ai/en/ai-principles)

??? note "Australian coordination mechanisms"

    **Whole-of-government coordination:**

    - National Security Committee of Cabinet
    - National Cabinet (federal-state coordination)
    - National Coordination Mechanism (emergency management)
    - Critical Infrastructure Centre

    **Sectoral coordination:**

    - Council of Financial Regulators (APRA, ASIC, RBA, Treasury)
    - Australian Health Ministers' Advisory Council
    - Education Council (federal and state education ministers)

---

