---
icon: lucide/building-2
tags:
  - Government
  - Policy
  - Governance
  - Research
---

# AI Safety Institutions and Capability

---

## Overview

This page examines **how different jurisdictions structure AI safety institutions**, drawing on international experience and Australia's own institutional strengths. It focuses on Australia's new AI Safety Institute (AISI) as a foundation and explores design choices governments typically face as AI safety frameworks mature.

!!! info "Australia's foundation: The AISI"

    In November 2025, Australia announced the **Australian AI Safety Institute (AISI)** with $29.9 million in funding, operational in early 2026. The AISI establishes dedicated evaluation capability and positions Australia as an equal partner in the International Network of AI Safety Institutes—addressing the most critical gap in Australia's AI safety ecosystem.

**What this page covers:**

- The AISI's role and how it positions Australia internationally
- Design questions governments typically address as AI safety frameworks mature
- How different jurisdictions coordinate across agencies and sectors
- Options for integrating AI safety with national security and resilience frameworks

This page examines international approaches and design choices, not to prescribe specific solutions, but to inform thinking about how institutional frameworks evolve over time.

---

## Australian AI Safety Institute: What it addresses

The AISI announcement represents a significant institutional development: a dedicated AI safety body with concentrated expertise. The AISI is expected to:

**Evaluation capability:**

- Test and evaluate advanced AI systems for safety
- Develop evaluation methodologies and frameworks
- Build technical expertise in AI safety assessment

**Standards and guidance:**

- Develop guidance and standards for AI development and deployment
- Support industry in implementing safety practices
- Contribute to regulatory frameworks

**International coordination:**

- Participate in the International Network of AI Safety Institutes
- Coordinate with UK, US and other safety institutes
- Share evaluation methodologies and threat intelligence

**Research and capability:**

- Work with researchers, industry and government
- Build domestic expertise in AI safety
- Support safety research relevant to Australian context

!!! success "What this achieves"

    The AISI addresses the most critical gap: Australia lacked dedicated technical capability to evaluate AI systems independently. The AISI provides concentrated expertise, cross-sectoral perspective, and ability to engage internationally on equal footing with UK and US counterparts.

---

## Design questions as frameworks mature

The AISI provides Australia's foundation for AI safety evaluation and international coordination. As with any new institution, design choices will evolve as the AISI becomes operational and government gains experience implementing AI safety frameworks. International experience suggests several questions typically arise:

!!! question "Common design considerations from international practice"

    Different jurisdictions structure their AI safety institutions differently, reflecting their governmental systems, regulatory traditions, and resource constraints. As Australia's framework matures, these are questions other countries have addressed:

    **1. How evaluation connects to regulatory authority**

    The AISI's role focuses on evaluation, standards and guidance. International examples show different approaches to connecting evaluation results to regulatory decisions:

    - **UK model:** AISI evaluates; sectoral regulators decide using existing authority
    - **US model:** NIST provides frameworks; agencies implement in their domains
    - **EU model:** AI Office coordinates; member state authorities enforce

    Questions this raises:
    - Who has authority to require evaluations or block deployments?
    - How do evaluation results inform regulatory decisions across different sectors?
    - What role does AISI play vs. sectoral regulators?

    **2. Sectoral regulator coordination**

    AI risks cut across sectors. Each jurisdiction addresses how sectoral regulators coordinate with central evaluation bodies:

    Examples of Australian sectoral regulators:
    - APRA (prudential regulation) for AI in financial services
    - TGA (Therapeutic Goods Administration) for AI medical devices
    - OAIC (Privacy Commissioner) for AI data governance
    - ACCC (competition) for AI market concentration
    - State regulators for health, education, justice

    International models show different coordination approaches—from formal memoranda of understanding to informal liaison arrangements.

    **3. Whole-of-government coordination**

    The AISI provides concentrated technical capability. Other jurisdictions use various mechanisms for cross-government coordination:

    - Preventing gaps (risks that fall between agencies)
    - Preventing duplication (multiple agencies addressing same issues)
    - Information sharing and joint decision-making
    - Integration with national security and resilience frameworks

    See [Coordination](coordination.md) for detailed examination of different approaches.

    ---


## Design principles for institutional frameworks

International practice and research suggest several key principles:

**Clarity about roles and authority:**

- Every institution should know what they're responsible for and what authority they have
- Ambiguity creates gaps; gaps create unmanaged risks

**Distributed expertise with central coordination:**

- AI risks cut across sectors—no single body has all expertise needed
- Leverage sectoral regulators who understand their domains
- Create coordination mechanisms to prevent gaps and duplication

**Independence with accountability:**

- Technical judgements insulated from commercial and political pressure
- Clear accountability through reporting and parliamentary oversight
- Transparency about how decisions are made

**Capability before crisis:**

- Building expertise, relationships and systems during crisis is too late
- Investment needed now, even when risks seem distant

**Adaptability as capabilities evolve:**

- Mechanisms for updating mandates and thresholds
- Regular review of whether structures remain fit-for-purpose
- Flexibility to respond to unexpected developments

For detailed analysis of institutional design options and trade-offs, see the [For Researchers](../for-researchers.md#institutional-design) section.

---

## Building capability: people, systems, resources

Institutional design on paper means nothing without capability to deliver.

**The AISI represents significant progress:** $29.9 million in funding, technical expertise in AI safety evaluation, international partnerships through the AI Safety Institutes Network, and capacity for research and standards development. This addresses Australia's most critical gap—the ability to independently evaluate AI systems rather than relying solely on provider claims or overseas assessments.

**What still needs building:**

Sectoral regulators need their own technical expertise to understand AI risks in their specific domains—APRA for financial services, TGA for medical devices, OAIC for privacy and data governance. These regulators know their sectors intimately but may lack the AI safety expertise to assess whether systems meet their regulatory requirements. Building this distributed expertise takes time, competitive salaries to attract specialists, and often partnerships with universities.

Infrastructure requirements extend beyond evaluation facilities. Secure infrastructure is needed for handling sensitive information about system capabilities—information that could be weaponised if leaked. Coordination systems must connect AISI evaluations with regulatory decisions. Communication and decision-making systems must function when AI-dependent systems fail, requiring manual processes and non-AI fallbacks.

**Funding challenges:**

Building capability requires multi-year budget commitments, not one-off investments. Technical expertise takes years to develop, international relationships require sustained engagement, and evaluation methodologies evolve as systems become more capable. This means baseline funding for regulators, ongoing research funding for universities, and contingency resources for rapid response to unexpected capabilities or failures.

**Talent and retention:**

International recruitment can help where Australia's domestic talent pool is limited—we don't have a large AI industry, so deep technical expertise is scarce. Clear career pathways matter: talented people need to see a long-term future in public sector AI work. Some countries address this through competitive salary bands for specialist roles, others through prestige and mission-driven work, most through some combination.

The AISI provides a foundation, but comprehensive capability requires sustained investment across the entire institutional ecosystem.

For detailed discussion of capability building approaches and trade-offs, see the [For Researchers](../for-researchers.md#institutional-design) section.

---

## How Australia is positioned

!!! success "Australia's institutional foundation"

    The AISI announcement positions Australia well for AI safety implementation:

    **What Australia has established:**

    - Independent evaluation capability through the AISI
    - Technical expertise dedicated to AI safety
    - Equal partnership in International Network of AI Safety Institutes
    - Standards and guidance development capacity

    **Australia's existing strengths:**

    - Strong sectoral regulators (APRA, TGA, OAIC, ACCC) with established authority
    - Effective coordination mechanisms (National Security Committee, National Cabinet, Critical Infrastructure Centre)
    - History of successful whole-of-government responses (COVID, bushfires, cyber incidents)
    - Trusted international partnerships through Five Eyes and AUKUS

    **Design choices ahead as frameworks mature:**

    - How evaluation connects to regulatory authority in different sectors
    - Coordination mechanisms between AISI and sectoral regulators
    - Federal-state cooperation building on existing models
    - Integration with national security and resilience frameworks

    **International experience shows:**

    - Evaluation bodies work best alongside clear coordination with regulators
    - Institutional design evolves as governments gain implementation experience
    - Capability building takes sustained investment over years
    - Flexibility to adapt as risks evolve is essential

---

## Sources & Further Reading

??? note "International institutional models"

    **UK approach:**

    - [UK AI Safety Institute](https://www.gov.uk/government/organisations/ai-safety-institute) (dedicated evaluation and safety research body)
    - [UK regulatory framework](https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach) (distributed regulators with coordination)

    **US approach:**

    - [US AI Safety Institute](https://www.nist.gov/aisi) (within NIST)
    - [National AI Initiative Office](https://www.ai.gov/) (coordination across agencies)
    - Sectoral approach: FDA for medical devices, FTC for consumer protection, etc.

    **EU approach:**

    - [EU AI Office](https://digital-strategy.ec.europa.eu/en/policies/ai-office) (implements EU AI Act)
    - [AI Act governance structure](https://artificialintelligenceact.eu/governance/) (Board, Office, national authorities)

    **Singapore:**

    - [AI Verify Foundation](https://aiverifyfoundation.sg/) (testing and governance tools)
    - [Model AI Governance Framework](https://www.pdpc.gov.sg/help-and-resources/2020/01/model-ai-governance-framework)

??? note "Australian context"

    **Australian AI Safety Institute:**

    - [Announcement and details](https://www.industry.gov.au/) (November 2025)
    - [National AI Plan](https://www.industry.gov.au/sites/default/files/2025-12/national-ai-plan.pdf) (December 2025)

    **Australian regulatory models:**

    - [Australian Prudential Regulation Authority](https://www.apra.gov.au/) (APRA)
    - [Australian Competition and Consumer Commission](https://www.accc.gov.au/) (ACCC)
    - [Office of the Australian Information Commissioner](https://www.oaic.gov.au/) (OAIC)
    - [Critical Infrastructure Centre](https://www.homeaffairs.gov.au/about-us/our-portfolios/national-security/security-coordination/critical-infrastructure-centre)

    **Coordination mechanisms:**

    - National Security Committee of Cabinet
    - National Cabinet (federal-state coordination)
    - National Coordination Mechanism (emergency management)

---

